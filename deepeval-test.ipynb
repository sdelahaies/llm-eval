{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/test-llm-eval/.venv/lib/python3.10/site-packages/deepeval/__init__.py:51: UserWarning: You are using deepeval version 2.1.7, however version 2.1.8 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n",
      "ðŸ™Œ Congratulations! You're now using a local model for all evals that require an\n",
      "LLM.\n"
     ]
    }
   ],
   "source": [
    "!deepeval set-local-model --model-name=phi4 --base-url=\"http://localhost:11434/v1/\" --api-key=\"ollama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_relevancy.py\n"
     ]
    }
   ],
   "source": [
    "%%file test_relevancy.py\n",
    "from deepeval import assert_test\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.metrics import AnswerRelevancyMetric\n",
    "\n",
    "\n",
    "def test_relevancy():\n",
    "    relevancy_metric = AnswerRelevancyMetric(threshold=0.5, model=\"gpt-4o\")\n",
    "    test_case_1 = LLMTestCase(\n",
    "        input=\"Can I return these shoes after 30 days?\",\n",
    "        actual_output=\"Unfortunately, returns are only accepted within 30 days of purchase.\",\n",
    "        retrieval_context=[\n",
    "            \"All customers are eligible for a 30-day full refund at no extra cost.\",\n",
    "            \"Returns are only accepted within 30 days of purchase.\",\n",
    "        ],\n",
    "    )\n",
    "    assert_test(test_case_1, [relevancy_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/test-llm-eval/.venv/lib/python3.10/site-packages/deepeval/__init__.py:51: UserWarning: You are using deepeval version 2.1.7, however version 2.1.8 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n",
      "Evaluating 1 test case(s) in parallel: |â–ˆ|100% (1/1) [Time Taken: 00:07,  7.91s/\n",
      "\u001b[32m.\u001b[0mRunning teardown with pytest sessionfinish\u001b[33m...\u001b[0m\n",
      "\n",
      "============================= slowest 10 durations =============================\n",
      "8.01s call     test_relevancy.py::test_relevancy\n",
      "\n",
      "(2 durations < 0.005s hidden.  Use -vv to show these durations.)\n",
      "\u001b[33m\u001b[32m1 passed\u001b[0m, \u001b[33m\u001b[1m2 warnings\u001b[0m\u001b[33m in 8.02s\u001b[0m\u001b[0m\n",
      "\u001b[3m                                  Test Results                                  \u001b[0m\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
      "â”ƒ\u001b[1m                \u001b[0mâ”ƒ\u001b[1m                 \u001b[0mâ”ƒ\u001b[1m                \u001b[0mâ”ƒ\u001b[1m        \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOverall Success\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
      "â”ƒ\u001b[1m \u001b[0m\u001b[1mTest case     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mMetric         \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mScore         \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mStatus\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mRate           \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
      "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
      "â”‚ test_relevancy â”‚                 â”‚                â”‚        â”‚ 100.0%          â”‚\n",
      "â”‚                â”‚ Answer          â”‚ 1.0            â”‚ \u001b[32mPASSED\u001b[0m â”‚                 â”‚\n",
      "â”‚                â”‚ Relevancy       â”‚ (threshold=0.â€¦ â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ evaluation     â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ model=local    â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ model,         â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ reason=The     â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ score is 1.00  â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ because the    â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ response       â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ directly       â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ addresses the  â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ input question â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ about          â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ returning      â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ shoes after 30 â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ days, with no  â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ irrelevant     â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ information    â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ present.,      â”‚        â”‚                 â”‚\n",
      "â”‚                â”‚                 â”‚ error=None)    â”‚        â”‚                 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "Total estimated evaluation tokens cost: \u001b[1;36m0.0\u001b[0m USD\n",
      "\u001b[92mâœ“\u001b[0m Tests finished ðŸŽ‰! Run \u001b[32m'deepeval login'\u001b[0m to save and analyze evaluation results\n",
      "on Confident AI. \n",
      "â€¼ï¸  Friendly reminder ðŸ˜‡: You can also run evaluations with ALL of deepeval's \n",
      "metrics directly on Confident AI instead.\n"
     ]
    }
   ],
   "source": [
    "!deepeval test run test_relevancy.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
