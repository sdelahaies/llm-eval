{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deepeval-mmlu\n",
    "\n",
    "code reproduced from https://www.datacamp.com/tutorial/deepeval consult the source for extended comments and explanation\n",
    "\n",
    "This notebook demonstrates how to configure, load, and evaluate a custom large language model (LLM) using the DeepEval library on the MMLU (Massive Multitask Language Understanding) benchmark. The focus is on benchmarking the performance of a quantized version of the Qwen2.5 7B Instruct model, optimized for efficient inference, on specific academic tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "import torch, logging \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "class QwenModel(DeepEvalBaseLLM):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = \"cuda\"\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        prompt = prompt.replace(\"Output 'A', 'B', 'C', or 'D'. Full answer not needed.\",\"\")\n",
    "        model_inputs = self.tokenizer([prompt], return_tensors=\"pt\").to(self.device)\n",
    "        generated_ids = self.model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=2,\n",
    "            do_sample=True,\n",
    "            pad_token_id=self.tokenizer.eos_token_id\n",
    "        )\n",
    "        prompt_length = len(model_inputs[0])\n",
    "        generated_tokens = generated_ids[0][prompt_length:]\n",
    "        clean_output = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "        return clean_output.replace(\".\",\"\")\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        return self.generate(prompt)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Qwen2.5 7B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name: str):\n",
    "    quant_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_use_double_quant=False\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quant_config,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    model.config.use_cache = False\n",
    "    model.config.pretraining_tp = 1\n",
    "    return model\n",
    "\n",
    "def load_tokenizer(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.padding_side = \"right\"\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da33bd37297a418ba6c4abcf26696862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7646539a3ad34c00acad22fa5e500a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a04a9fcfec44f89e12dcb5abebd3c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94729a7a2042413fa393872c348547b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7080ac5473040098638eb99d955af38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1dd12d18f984f509b1ba0501eadc967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/3.86G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ff512773b7440abc15820a757eb94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.56G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237a5488b3b347cca65203f0153735e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb91f6f993d4013a75735e5724ff51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94c42a5f71b54456ace3b6c1205ccc12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0daad4163649499eb923d6e2a4f6643a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce511f1905e4400bce24143126c6d20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb54f17bf1374b098d91dfdf91eed979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "qwen_model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "model = load_model(qwen_model_name)\n",
    "tokenizer = load_tokenizer(qwen_model_name)\n",
    "custom_model = QwenModel(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "# Test model generation\n",
    "\n",
    "prompt = \"\"\"\n",
    "The following are multiple choice questions (with answers) about abstract algebra.\n",
    "\n",
    "Find all c in Z_3 such that Z_3[x]/(x^2 + c) is a field.\n",
    "A. 0\n",
    "B. 1\n",
    "C. 2\n",
    "D. 3\n",
    "Answer:\"\"\"\n",
    "print(custom_model.generate(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da20899fe6e74e29acba63653341a9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/28.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabff30d976e4f7bbac8bf16fec3a6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mmlu.py:   0%|          | 0.00/5.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59697a8440c64af8aaef7346cacd22f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/166M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f691c428858c4fbdae6ec4239e274f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13684687587348c58292e7212102d90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/9 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe59f43d6e440a8a571d73b3d900b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing high_school_computer_science: 100%|██████████| 100/100 [00:36<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMLU Task Accuracy (task=high_school_computer_science): 0.85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414be31c80e249d98086d1f419c19207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3eefaee31f4e5bb88d691671fbddde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17fcdbdeeb6d4d7d9a1940f98ef65d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing astronomy: 100%|██████████| 152/152 [00:54<00:00,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMLU Task Accuracy (task=astronomy): 0.8092105263157895\n",
      "Overall MMLU Accuracy: 0.8253968253968254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8253968253968254"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deepeval.benchmarks import MMLU\n",
    "from deepeval.benchmarks.tasks import MMLUTask\n",
    "\n",
    "# Define benchmark with specific tasks and shots\n",
    "benchmark = MMLU(\n",
    "    tasks=[MMLUTask.HIGH_SCHOOL_COMPUTER_SCIENCE, MMLUTask.ASTRONOMY],\n",
    "    n_shots=5\n",
    ")\n",
    "\n",
    "benchmark.evaluate(model=custom_model, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>0.809211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Task     Score\n",
       "0  high_school_computer_science  0.850000\n",
       "1                     astronomy  0.809211"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.task_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th>Input</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Expected Output</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>Let x = 1. What is x &lt;&lt; 3 in Python 3?\\nA. 1\\n...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>In Python 3, which of the following function c...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>A user enters a Web address in a browser, and ...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>Digital images are often represented by the re...</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high_school_computer_science</td>\n",
       "      <td>A programmer is writing a program that is inte...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>Find the best approximation for the surface te...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>Previous IAAC rounds featured Proxima/Alpha Ce...</td>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>How are planetary rings made?\\nA. From the dis...</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>The lunar maria are:\\nA. ancient heavily crate...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>astronomy</td>\n",
       "      <td>One astronomical unit (AU) is equal to approxi...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Task  \\\n",
       "0    high_school_computer_science   \n",
       "1    high_school_computer_science   \n",
       "2    high_school_computer_science   \n",
       "3    high_school_computer_science   \n",
       "4    high_school_computer_science   \n",
       "..                            ...   \n",
       "247                     astronomy   \n",
       "248                     astronomy   \n",
       "249                     astronomy   \n",
       "250                     astronomy   \n",
       "251                     astronomy   \n",
       "\n",
       "                                                 Input Prediction  \\\n",
       "0    Let x = 1. What is x << 3 in Python 3?\\nA. 1\\n...          C   \n",
       "1    In Python 3, which of the following function c...          A   \n",
       "2    A user enters a Web address in a browser, and ...          A   \n",
       "3    Digital images are often represented by the re...          B   \n",
       "4    A programmer is writing a program that is inte...          B   \n",
       "..                                                 ...        ...   \n",
       "247  Find the best approximation for the surface te...          A   \n",
       "248  Previous IAAC rounds featured Proxima/Alpha Ce...          C   \n",
       "249  How are planetary rings made?\\nA. From the dis...          B   \n",
       "250  The lunar maria are:\\nA. ancient heavily crate...          C   \n",
       "251  One astronomical unit (AU) is equal to approxi...          B   \n",
       "\n",
       "    Expected Output  Correct  \n",
       "0                 C        1  \n",
       "1                 A        1  \n",
       "2                 A        1  \n",
       "3                 C        0  \n",
       "4                 B        1  \n",
       "..              ...      ...  \n",
       "247               A        1  \n",
       "248               D        0  \n",
       "249               A        0  \n",
       "250               C        1  \n",
       "251               B        1  \n",
       "\n",
       "[252 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark.predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
